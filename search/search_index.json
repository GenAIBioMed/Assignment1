{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Assignment 1: Finetuning ProGen2 on Green Fluorescent Protein","text":"<p>ProGen2 is a foundation model for protein design. For detailed information, please check paper</p> <p>In this assignment, you'll learn how to finetune the pretrained ProGen2 model on a specific protein family, e.g., green fluorescent protein. Then you'll need to apply AlphaFold3 metrics to select good candidates which are highly potential to  have the desired function from your finetuned model.</p> <p></p>"},{"location":"#environment-setup","title":"Environment Setup","text":"<p>The starting code base is provided in GenAIBioMed/Assignment1.git.</p> <p>Prerequisites: You'll need a GPU to complete this assignment. We recommend PSC supercomputing center, which has already provided to you.</p> <p>The environments to finetune the model and generate proteins are provided below.  Please make sure your python version is 3.9+.</p> <pre><code>python3 -m venv progen \nsource progen/bin/activate \npip install torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu128\npip install transformers==4.49.0\n</code></pre> <p>If you choose to use anaconda, run the following command [Preferred method for PSC] </p> <p>On PSC : you can load conda through <code>module load anaconda3/2024.10-1</code></p> <pre><code>conda create -n progen python=3.9.16 -y \nconda activate progen \npip install torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu128\npip install transformers==4.49.0\n</code></pre>"},{"location":"#downloading-pretrained-models","title":"Downloading Pretrained models","text":"<p>To prepare the pretrained model for subsequence finetuning process,  please run the following command:</p> <pre><code>mkdir pretrained_model\nmkdir models\nmkdir pretrained_model/progen2-small\ncd pretrained_model/progen2-small\nwget https://storage.googleapis.com/sfr-progen-research/checkpoints/progen2-small.tar.gz\ntar -xvzf progen2-small.tar.gz\n</code></pre>"},{"location":"#finetuning","title":"Finetuning","text":"<p>We already provided the full training pipeline. What you need to do  is finish the TODO modules in the current code. If you have problem in filling the code, please refer to the hints. Please Don't change the other parts, especially the seed and the hyperparameters we give notes for.</p> <p>After filling all the core code lines, please follow the command below to finetune the model: </p> <pre><code>python train.py\n</code></pre>"},{"location":"#design","title":"Design","text":"<p>After finetuning the model, we use the best checkpoints from your finetuning process to design functional green fluorescent proteins. To achieve this goal, we'll provide the first 64 tokens as the prompt to the model and then the finetuned model will generate a full protein sequence autoregressively conditioned on the provided prompt. To achieve design, just follow the command below:</p> <pre><code>python inference.py\n</code></pre>"},{"location":"#candidate-selection","title":"Candidate Selection","text":"<p>After generating a set of candidates, we will select high-quality candidates using AlphaFold3 metrics.</p> <p>For AlphaFold3, you can either use the code from the GitHub repo or use their web server. </p> <p>If you choose to use the GitHub repo, please follow their official guidelines. </p> <p>If you choose to use the web server, please follow the instruction below:</p>"},{"location":"#running-alphafold3-evaluation","title":"Running AlphaFold3 Evaluation","text":"<p>The AlphaFold3 website server is at link.  To run the evaluation, follow the instruction below:</p> <p>(1) Register an account using your gmail account</p> <p>(2) Input your designed sequence to the protein field as below:</p> <p></p> <p>(3) click continue and preview job, and then click Confirm and submit job:</p> <p></p> <p>(4) After waiting some time, you\u2019ll have the results:</p> <p></p> <p>(5) Among all the designed sequences, rank them according to their pLDDT scores, which can be calculated based on the folded structure</p> <p>(6) Find the top-5 candidates with the highest pLDDT, of which the pTM scores should be higher than 0.8. If not, there might be something wrong with your finetuning process</p>"},{"location":"#submit-your-results","title":"Submit Your Results","text":"<p>Please compress all the results into a zip file, and the results should include:</p> <p>(1) The fully filled code. Note don\u2019t submit the data but only submit the python files</p> <p>(2) A PDF file for the top 5 candidate report. Please include the detailed information about your top-5 candiates, including the Alphafold3 visualization, sequences, pTM score, pLDDT score, and provide an explanation of these metrics.</p>"}]}